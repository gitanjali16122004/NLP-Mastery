{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHJicHBitkfglq5i/dS58/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitanjali16122004/NLP-Mastery/blob/main/Tokenization_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "XnQnaPkohBeo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nFXwR3lV_vL",
        "outputId": "4d8c9098-323b-4d10-aa1d-486e6a45bef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "nltk.download('punkt_tab')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Elon Musk announced a new AI project last week.\"\n",
        "tokens = text.split()\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBww3rglYkRX",
        "outputId": "e7f0d676-94b0-42da-d736-af281da02319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Elon', 'Musk', 'announced', 'a', 'new', 'AI', 'project', 'last', 'week.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Elon Musk announced a new AI project. It was a breakthrough.\"\n",
        "sentences = text.split(\".\")\n",
        "sentences = [s.strip() for s in sentences if s.strip()]\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBbVEN0TY1mL",
        "outputId": "e16245b6-90e1-41ee-9e14-3af32ca14cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Elon Musk announced a new AI project', 'It was a breakthrough']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is not handle the abbrevation like \"Dr.\",\"U.S\"\n",
        "text = \"Dr. Elon Musk announced a new AI project. It was a breakthrough.\"\n",
        "sentences = text.split(\".\")\n",
        "sentences = [s.strip() for s in sentences if s.strip()]\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr79IMVSZEPD",
        "outputId": "2b1fa8cb-03f3-4e6a-8c1a-947b764383ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dr', 'Elon Musk announced a new AI project', 'It was a breakthrough']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(\"Hii,How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3Krkj9EWHVA",
        "outputId": "31a375fb-dfd0-4dda-eefc-8f433eb740b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hii', ',', 'How', 'are', 'you', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"Elon Musk, the CEO of Tesla and SpaceX, announced a new AI project last week.\",\n",
        "    \"The Eiffel Tower in Paris attracts millions of tourists every year.\",\n",
        "    \"NASA successfully landed the Perseverance rover on Mars in 2021.\",\n",
        "    \"The stock market saw a sharp decline due to economic instability.\",\n",
        "    \"COVID-19 had a significant impact on global healthcare and economies.\",\n",
        "    \"The Amazon rainforest plays a crucial role in Earth's climate system.\",\n",
        "    \"Artificial Intelligence and Machine Learning are transforming industries worldwide.\"\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "X4HRyHU_XPCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for NLTK tokenization\n",
        "def nltk_tokenization(text):\n",
        "    words = word_tokenize(text)  # Word Tokenization\n",
        "    sentences = sent_tokenize(text)  # Sentence Tokenization\n",
        "    return words, sentences\n",
        "\n",
        "# Apply tokenization to the corpus\n",
        "for i, text in enumerate(corpus):\n",
        "    nltk_words, nltk_sentences = nltk_tokenization(text)\n",
        "\n",
        "    print(f\"\\nSentence {i+1}: {text}\")\n",
        "    print(\"NLTK Word Tokens:\", nltk_words)\n",
        "    print(\"NLTK Sentence Tokens:\", nltk_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkqtnCxoao0v",
        "outputId": "91144c4a-b8ae-43a9-d097-546eae8740df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence 1: Elon Musk, the CEO of Tesla and SpaceX, announced a new AI project last week.\n",
            "NLTK Word Tokens: ['Elon', 'Musk', ',', 'the', 'CEO', 'of', 'Tesla', 'and', 'SpaceX', ',', 'announced', 'a', 'new', 'AI', 'project', 'last', 'week', '.']\n",
            "NLTK Sentence Tokens: ['Elon Musk, the CEO of Tesla and SpaceX, announced a new AI project last week.']\n",
            "\n",
            "Sentence 2: The Eiffel Tower in Paris attracts millions of tourists every year.\n",
            "NLTK Word Tokens: ['The', 'Eiffel', 'Tower', 'in', 'Paris', 'attracts', 'millions', 'of', 'tourists', 'every', 'year', '.']\n",
            "NLTK Sentence Tokens: ['The Eiffel Tower in Paris attracts millions of tourists every year.']\n",
            "\n",
            "Sentence 3: NASA successfully landed the Perseverance rover on Mars in 2021.\n",
            "NLTK Word Tokens: ['NASA', 'successfully', 'landed', 'the', 'Perseverance', 'rover', 'on', 'Mars', 'in', '2021', '.']\n",
            "NLTK Sentence Tokens: ['NASA successfully landed the Perseverance rover on Mars in 2021.']\n",
            "\n",
            "Sentence 4: The stock market saw a sharp decline due to economic instability.\n",
            "NLTK Word Tokens: ['The', 'stock', 'market', 'saw', 'a', 'sharp', 'decline', 'due', 'to', 'economic', 'instability', '.']\n",
            "NLTK Sentence Tokens: ['The stock market saw a sharp decline due to economic instability.']\n",
            "\n",
            "Sentence 5: COVID-19 had a significant impact on global healthcare and economies.\n",
            "NLTK Word Tokens: ['COVID-19', 'had', 'a', 'significant', 'impact', 'on', 'global', 'healthcare', 'and', 'economies', '.']\n",
            "NLTK Sentence Tokens: ['COVID-19 had a significant impact on global healthcare and economies.']\n",
            "\n",
            "Sentence 6: The Amazon rainforest plays a crucial role in Earth's climate system.\n",
            "NLTK Word Tokens: ['The', 'Amazon', 'rainforest', 'plays', 'a', 'crucial', 'role', 'in', 'Earth', \"'s\", 'climate', 'system', '.']\n",
            "NLTK Sentence Tokens: [\"The Amazon rainforest plays a crucial role in Earth's climate system.\"]\n",
            "\n",
            "Sentence 7: Artificial Intelligence and Machine Learning are transforming industries worldwide.\n",
            "NLTK Word Tokens: ['Artificial', 'Intelligence', 'and', 'Machine', 'Learning', 'are', 'transforming', 'industries', 'worldwide', '.']\n",
            "NLTK Sentence Tokens: ['Artificial Intelligence and Machine Learning are transforming industries worldwide.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stopword Removal"
      ],
      "metadata": {
        "id": "K2JvRxmCgyUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"Hello, world! How are you?\"\n",
        "doc = nlp(text)\n",
        "tokens = [token.text for token in doc]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b9tgOhOazw9",
        "outputId": "b77b9a5b-9cb0-4ca2-9944-f49d8bf27a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '!', 'How', 'are', 'you', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "text = \"Hello @user! ðŸ˜Š #HappyDay\"\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmJbHk6fb-a7",
        "outputId": "8f009739-ec21-4fb1-fd58-6204953afbd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', '@user', '!', 'ðŸ˜Š', '#HappyDay']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.corpus import stopwords\n",
        "# Download required resources\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jks-dwIcEeh",
        "outputId": "fdca7961-3c50-4dda-9dc4-06049038c812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "corpus = [\n",
        "    \"Elon Musk, the CEO of Tesla and SpaceX, announced a new AI project last week.\",\n",
        "    \"The Eiffel Tower in Paris attracts millions of tourists every year.\",\n",
        "    \"NASA successfully landed the Perseverance rover on Mars in 2021.\",\n",
        "    \"The stock market saw a sharp decline due to economic instability.\",\n",
        "    \"COVID-19 had a significant impact on global healthcare and economies.\",\n",
        "    \"The Amazon rainforest plays a crucial role in Earth's climate system.\",\n",
        "    \"Artificial Intelligence and Machine Learning are transforming industries worldwide.\"\n",
        "]"
      ],
      "metadata": {
        "id": "wS5jTz9TgGfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    words = word_tokenize(text)  # Tokenize the sentence\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]  # Remove stopwords\n",
        "    return filtered_words\n",
        "\n",
        "# Apply stopword removal to the corpus\n",
        "for i, text in enumerate(corpus):\n",
        "    filtered_tokens = remove_stopwords(text)\n",
        "\n",
        "    print(f\"\\nOriginal Sentence {i+1}: {text}\")\n",
        "    print(\"Filtered Tokens (Without Stopwords):\", filtered_tokens)\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlBvWnhWgJM4",
        "outputId": "b13d760f-33f5-42a7-f1a5-c774d9588861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original Sentence 1: Elon Musk, the CEO of Tesla and SpaceX, announced a new AI project last week.\n",
            "Filtered Tokens (Without Stopwords): ['Elon', 'Musk', ',', 'CEO', 'Tesla', 'SpaceX', ',', 'announced', 'new', 'AI', 'project', 'last', 'week', '.']\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Original Sentence 2: The Eiffel Tower in Paris attracts millions of tourists every year.\n",
            "Filtered Tokens (Without Stopwords): ['Eiffel', 'Tower', 'Paris', 'attracts', 'millions', 'tourists', 'every', 'year', '.']\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Original Sentence 3: NASA successfully landed the Perseverance rover on Mars in 2021.\n",
            "Filtered Tokens (Without Stopwords): ['NASA', 'successfully', 'landed', 'Perseverance', 'rover', 'Mars', '2021', '.']\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Original Sentence 4: The stock market saw a sharp decline due to economic instability.\n",
            "Filtered Tokens (Without Stopwords): ['stock', 'market', 'saw', 'sharp', 'decline', 'due', 'economic', 'instability', '.']\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Original Sentence 5: COVID-19 had a significant impact on global healthcare and economies.\n",
            "Filtered Tokens (Without Stopwords): ['COVID-19', 'significant', 'impact', 'global', 'healthcare', 'economies', '.']\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Original Sentence 6: The Amazon rainforest plays a crucial role in Earth's climate system.\n",
            "Filtered Tokens (Without Stopwords): ['Amazon', 'rainforest', 'plays', 'crucial', 'role', 'Earth', \"'s\", 'climate', 'system', '.']\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Original Sentence 7: Artificial Intelligence and Machine Learning are transforming industries worldwide.\n",
            "Filtered Tokens (Without Stopwords): ['Artificial', 'Intelligence', 'Machine', 'Learning', 'transforming', 'industries', 'worldwide', '.']\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jfoNHhmGgQje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}